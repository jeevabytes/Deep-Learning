{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Spam Classification Using MLP with Backpropagation**"
      ],
      "metadata": {
        "id": "QK0ZbuQSId-E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing libraries"
      ],
      "metadata": {
        "id": "qKoLjOwpRmMM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "cnwkQ8px7gBG"
      },
      "outputs": [],
      "source": [
        "#importing necessary libraries\n",
        "import numpy as np              #for performing numerical operations\n",
        "import pandas as pd             #for handling structured data in the form of dataframes\n",
        "from sklearn.model_selection import train_test_split   #Splits data into training and testing sets\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer   #converts text data into numerical form using TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading dataset"
      ],
      "metadata": {
        "id": "Mqj86hdnSCe3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading dataset\n",
        "url=\"/content/spam.csv\"\n",
        "df=pd.read_csv(url)\n",
        "print(df.head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbsT0cxG8ug-",
        "outputId": "a967074b-6ef6-4d78-a05d-34e28e6e5a1a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method NDFrame.head of      Category                                            Message\n",
            "0         ham  Go until jurong point, crazy.. Available only ...\n",
            "1         ham                      Ok lar... Joking wif u oni...\n",
            "2        spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3         ham  U dun say so early hor... U c already then say...\n",
            "4         ham  Nah I don't think he goes to usf, he lives aro...\n",
            "...       ...                                                ...\n",
            "5567     spam  This is the 2nd time we have tried 2 contact u...\n",
            "5568      ham               Will ü b going to esplanade fr home?\n",
            "5569      ham  Pity, * was in mood for that. So...any other s...\n",
            "5570      ham  The guy did some bitching but I acted like i'd...\n",
            "5571      ham                         Rofl. Its true to its name\n",
            "\n",
            "[5572 rows x 2 columns]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing"
      ],
      "metadata": {
        "id": "AAPiQ8tpSI1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to binary (ham=0, spam=1)\n",
        "df['Category'] = df['Category'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# Convert text into numerical form using TF-IDF\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000) #stop_words='english': removes common English words like (\"the\", \"is\", \"a\") that do not carry meaningful information\n",
        "                                                                      #max_features=1000: Limits the vocabulary to the 1000 most important words across all messages\n",
        "\n",
        "X = vectorizer.fit_transform(df['Message']).toarray()  #converts text messages into a numerical feature matrix, where each row represents a message and each column corresponds to a word’s importance based on TF-IDF scores\n",
        "y = df['Category'].values.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "co5giQZMB_Gq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting Dataset"
      ],
      "metadata": {
        "id": "DHD6CsQmSPgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "pXzgQFQZCIHQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP Neural Network"
      ],
      "metadata": {
        "id": "GCh8a-JuSTlk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the MLP Neural Network\n",
        "class MLP:\n",
        "  #Defines network structure (input, hidden, output layers)\n",
        "    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.01):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        # Initialize weights and biases\n",
        "        self.W1 = np.random.randn(self.input_size, self.hidden_size)\n",
        "        self.b1 = np.zeros((1, self.hidden_size))\n",
        "        self.W2 = np.random.randn(self.hidden_size, self.output_size)\n",
        "        self.b2 = np.zeros((1, self.output_size))\n",
        "\n",
        "#Uses sigmoid activation for introducing non-linearity and calculates its derivative for backpropagation\n",
        "    def sigmoid(self, x):              #Converts input into probabilities (0 to 1)\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, x):   #Helps adjust weights during backpropagation\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def forward(self, X):             #Computes output by applying weights, biases, and activations layer by layer\n",
        "        self.z1 = np.dot(X, self.W1) + self.b1\n",
        "        self.a1 = self.sigmoid(self.z1)\n",
        "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
        "        self.a2 = self.sigmoid(self.z2)\n",
        "        return self.a2\n",
        "\n",
        "    def backward(self, X, y):\n",
        "        m = y.shape[0]\n",
        "\n",
        "        # Compute error\n",
        "        error = self.a2 - y\n",
        "        d_output = error * self.sigmoid_derivative(self.a2)\n",
        "\n",
        "        # Compute gradient for hidden layer\n",
        "        error_hidden = np.dot(d_output, self.W2.T)\n",
        "        d_hidden = error_hidden * self.sigmoid_derivative(self.a1)\n",
        "\n",
        "        # Update weights and biases\n",
        "        self.W2 -= self.learning_rate * np.dot(self.a1.T, d_output) / m\n",
        "        self.b2 -= self.learning_rate * np.sum(d_output, axis=0, keepdims=True) / m\n",
        "        self.W1 -= self.learning_rate * np.dot(X.T, d_hidden) / m\n",
        "        self.b1 -= self.learning_rate * np.sum(d_hidden, axis=0, keepdims=True) / m\n",
        "\n",
        "#Runs forward and backward propagation for a given number of epochs and prints loss every 100 iterations\n",
        "    def train(self, X, y, epochs=500):\n",
        "        for epoch in range(epochs):\n",
        "            self.forward(X)\n",
        "            self.backward(X, y)\n",
        "\n",
        "            if epoch % 100 == 0:\n",
        "                loss = np.mean((self.a2 - y) ** 2)\n",
        "                print(f\"Epoch {epoch}, Loss: {loss:.6f}\")\n",
        "\n",
        "#Performs forward propagation on new data\n",
        "    def predict(self, X):\n",
        "        return (self.forward(X) > 0.5).astype(int)  # Convert probabilities to binary classification(0 or 1)"
      ],
      "metadata": {
        "id": "uKWYwmz8CID2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training MLP"
      ],
      "metadata": {
        "id": "RteNZ8N9SY3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the MLP\n",
        "input_size = X_train.shape[1]  #number of input features from the training data which was transformed using TF-IDF\n",
        "hidden_size = 6   # Reduced from 10 → 6 neurons\n",
        "output_size = 1   # Binary classification (spam=1, ham=0)\n",
        "learning_rate = 0.01   # Controls how fast weights are updated\n",
        "\n",
        "#Creates an instance of the MLP class with the defined parameters\n",
        "mlp = MLP(input_size, hidden_size, output_size, learning_rate)\n",
        "mlp.train(X_train, y_train, epochs=500)   #Runs forward and backward propagation for 500 epochs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RM3NfHkRCIBQ",
        "outputId": "3481b9a8-7c29-433a-815e-eb33473d0cca"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.436880\n",
            "Epoch 100, Loss: 0.373241\n",
            "Epoch 200, Loss: 0.315451\n",
            "Epoch 300, Loss: 0.267669\n",
            "Epoch 400, Loss: 0.230799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predictions & Accuracy"
      ],
      "metadata": {
        "id": "2hWByxYuSb46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "predictions = mlp.predict(X_test)   #Uses the trained model to classify test messages\n",
        "\n",
        "# Accuracy Calculation\n",
        "accuracy = np.mean(predictions == y_test) * 100   #Compares predictions with actual labels and calculates percentage accuracy\n",
        "print(f\"Model Accuracy: {accuracy:.2f}%\")      #Displays the model’s performance in percentage form\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTWfld5aCH7d",
        "outputId": "de54d7cb-d949-4942-96bc-a2ffe0b0ad03"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 70.58%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion"
      ],
      "metadata": {
        "id": "JA8uoqiISmrx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code uses backpropagation to create a basic Multi-Layer Perceptron (MLP) neural network that can distinguish between spam and ham SMS messages.  It starts by loading and preparing the dataset, then utilizing TF-IDF vectorization to turn text messages into numerical features.  Next, training and testing sets are created from the dataset.  Using forward and backward propagation and gradient descent to update weights, a neural network with one hidden layer (6 neurons) is started and learns to differentiate between spam and ham messages.  Following 500 epochs of training, the model predicts on the test set, and accuracy is used to assess its performance."
      ],
      "metadata": {
        "id": "kICYRp6BSpfo"
      }
    }
  ]
}