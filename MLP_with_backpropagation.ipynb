{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **MLP with Backpropagation**"
      ],
      "metadata": {
        "id": "GQDb1YOqeEOP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing libraries"
      ],
      "metadata": {
        "id": "jT0aHtsXeMVm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CCVMJrTz75v8"
      },
      "outputs": [],
      "source": [
        "import numpy as np              #for performing numerical operations\n",
        "from sklearn.datasets import make_moons    #importing the dataset make_moons shaped like two interleaving half-moons\n",
        "from sklearn.preprocessing import OneHotEncoder   #converts categorical data into numerical format\n",
        "from sklearn.model_selection import train_test_split   #Splits data into training and testing sets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Multilayer Perceptron Class"
      ],
      "metadata": {
        "id": "WB1RtbXteRba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP:\n",
        "  def __init__(self,input_size,hidden_size,output_size,learning_rate=0.01):   #constructor method that runs when an object of the class is created\n",
        "    self.input_size=input_size\n",
        "    self.hidden_size=hidden_size\n",
        "    self.output_size=output_size\n",
        "    self.learning_rate=learning_rate                         #Defines how fast the neural network updates during learning (default is 0.01)\n",
        "\n",
        "    #Initialize weights and biases\n",
        "    #W1 - weights from input to hidden layer\n",
        "    self.W1=np.random.randn(self.input_size,self.hidden_size) #np.random.randn(rows,columns) generates random numbers from a normal distribution(ie.mean 0 & std 1)\n",
        "    #Bias for Hidden Layer\n",
        "    self.b1=np.zeros((1,self.hidden_size))\n",
        "    self.W2=np.random.randn(self.hidden_size,self.output_size)\n",
        "    self.b2=np.zeros((1,self.output_size))\n",
        "\n",
        "  def sigmoid(self,x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "  def sigmoid_derivative(self,x):\n",
        "    return x*(1-x)\n",
        "\n",
        "  def forward(self,X):\n",
        "    self.z1=np.dot(X,self.W1)+self.b1\n",
        "    self.a1=self.sigmoid(self.z1)\n",
        "    self.z2=np.dot(self.a1,self.W2)+self.b2\n",
        "    self.a2=self.sigmoid(self.z2)\n",
        "    return self.a2\n",
        "\n",
        "  def backward(self,X,y):\n",
        "    m=y.shape[0]\n",
        "\n",
        "    #compute error\n",
        "    error=self.a2-y\n",
        "    d_output=error*self.sigmoid_derivative(self.a2)\n",
        "\n",
        "    #compute gradient for hidden layer\n",
        "    error_hidden=np.dot(d_output,self.W2.T)\n",
        "    d_hidden=error_hidden*self.sigmoid_derivative(self.a1)\n",
        "\n",
        "    #update weights and biases\n",
        "    self.W2-=self.learning_rate*np.dot(self.a1.T,d_output)/m\n",
        "    self.b2-=self.learning_rate*np.sum(d_output,axis=0,keepdims=True)/m\n",
        "    self.W1-=self.learning_rate*np.dot(X.T,d_hidden)/m\n",
        "    self.b1-=self.learning_rate*np.sum(d_hidden,axis=0,keepdims=True)/m\n",
        "\n",
        "  def train(self,X,y,epochs=10000):\n",
        "      for epoch in range(epochs):\n",
        "        self.forward(X)\n",
        "        self.backward(X,y)\n",
        "\n",
        "        if epoch%1000==0:\n",
        "          loss=np.mean((self.a2-y)**2)\n",
        "          print(f\"Epoch {epoch},Loss:{loss:.6f}\")\n",
        "\n",
        "  def predict(self,X):\n",
        "      return self.forward(X)"
      ],
      "metadata": {
        "id": "GO68Ve-A8PVO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating & Splitting dataset for training"
      ],
      "metadata": {
        "id": "jKiGOgKleShD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate dataset\n",
        "X,y=make_moons(n_samples=500,noise=0.2,random_state=42)\n",
        "y=y.reshape(-1,1)  #reshape for compatibilty\n",
        "\n",
        "#split dataset\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "3WCJLu8WDASk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training MLP on the dataset"
      ],
      "metadata": {
        "id": "mUJM5PrweTOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train MLP\n",
        "mlp=MLP(input_size=2,hidden_size=4,output_size=1,learning_rate=0.1)\n",
        "mlp.train(X_train,y_train,epochs=10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilSIuOy0Gfd6",
        "outputId": "1d99efd0-d2d8-49a9-e3ef-25469314d3f2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0,Loss:0.292444\n",
            "Epoch 1000,Loss:0.136272\n",
            "Epoch 2000,Loss:0.104769\n",
            "Epoch 3000,Loss:0.097734\n",
            "Epoch 4000,Loss:0.094886\n",
            "Epoch 5000,Loss:0.093544\n",
            "Epoch 6000,Loss:0.092856\n",
            "Epoch 7000,Loss:0.092474\n",
            "Epoch 8000,Loss:0.092241\n",
            "Epoch 9000,Loss:0.092086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making predictions with the trained model"
      ],
      "metadata": {
        "id": "2UIRtJI7eUGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions\n",
        "predictions=mlp.predict(X_test)\n",
        "print(\"Predictions:\",predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsxUFpZDGpba",
        "outputId": "55620296-8418-41ca-c173-b2d3bab61222"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [[0.5212849 ]\n",
            " [0.22578535]\n",
            " [0.30887004]\n",
            " [0.95477961]\n",
            " [0.90046643]\n",
            " [0.80578014]\n",
            " [0.0370618 ]\n",
            " [0.07530319]\n",
            " [0.32053113]\n",
            " [0.08423896]\n",
            " [0.9489012 ]\n",
            " [0.04332643]\n",
            " [0.84212431]\n",
            " [0.84350749]\n",
            " [0.90512294]\n",
            " [0.05902108]\n",
            " [0.05502829]\n",
            " [0.90087697]\n",
            " [0.87372675]\n",
            " [0.15615662]\n",
            " [0.06278368]\n",
            " [0.50614901]\n",
            " [0.63661572]\n",
            " [0.25454836]\n",
            " [0.11915513]\n",
            " [0.17141618]\n",
            " [0.77462151]\n",
            " [0.04254255]\n",
            " [0.94049358]\n",
            " [0.04437501]\n",
            " [0.94640315]\n",
            " [0.96527257]\n",
            " [0.09651079]\n",
            " [0.03757103]\n",
            " [0.9468687 ]\n",
            " [0.62890452]\n",
            " [0.08246137]\n",
            " [0.95500495]\n",
            " [0.94000175]\n",
            " [0.90667445]\n",
            " [0.70712591]\n",
            " [0.83461281]\n",
            " [0.29360648]\n",
            " [0.06851406]\n",
            " [0.05404887]\n",
            " [0.14273632]\n",
            " [0.91579664]\n",
            " [0.13957984]\n",
            " [0.89346382]\n",
            " [0.29142201]\n",
            " [0.34204872]\n",
            " [0.95721958]\n",
            " [0.0562541 ]\n",
            " [0.05776491]\n",
            " [0.23686486]\n",
            " [0.07271768]\n",
            " [0.27220839]\n",
            " [0.94935337]\n",
            " [0.04084792]\n",
            " [0.93454827]\n",
            " [0.05857781]\n",
            " [0.91973263]\n",
            " [0.85554934]\n",
            " [0.06227643]\n",
            " [0.90175167]\n",
            " [0.09077296]\n",
            " [0.17469596]\n",
            " [0.75484127]\n",
            " [0.05272775]\n",
            " [0.65582296]\n",
            " [0.56019234]\n",
            " [0.12194513]\n",
            " [0.87335439]\n",
            " [0.9138886 ]\n",
            " [0.04991854]\n",
            " [0.05061459]\n",
            " [0.95768365]\n",
            " [0.95186053]\n",
            " [0.04827714]\n",
            " [0.10414665]\n",
            " [0.86461604]\n",
            " [0.31581746]\n",
            " [0.24498223]\n",
            " [0.67056514]\n",
            " [0.93823895]\n",
            " [0.93475383]\n",
            " [0.90445965]\n",
            " [0.06506459]\n",
            " [0.94675485]\n",
            " [0.86972986]\n",
            " [0.9389095 ]\n",
            " [0.05116882]\n",
            " [0.07685288]\n",
            " [0.08595951]\n",
            " [0.0562377 ]\n",
            " [0.9297661 ]\n",
            " [0.05440006]\n",
            " [0.72242577]\n",
            " [0.36022341]\n",
            " [0.95503882]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion"
      ],
      "metadata": {
        "id": "aTsuK0KNeVlA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The moons dataset is a frequent nonlinear classification issue that the developed Multi-Layer Perceptron (MLP) is intended to categorize.  Using the sigmoid activation function, the network is composed of an input layer with two neurons, a hidden layer with four neurons, and an output layer with one neuron.  Backpropagation and gradient descent are used for training, and in order to minimize error, weights and biases are changed iteratively across 10,000 epochs.  The model shows how a basic neural network can manage intricate decision boundaries by successfully learning to distinguish between the two classes."
      ],
      "metadata": {
        "id": "ISATRp7eeW4E"
      }
    }
  ]
}