{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Perceptron Model**"
      ],
      "metadata": {
        "id": "WWJBlmEJVZQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "class perceptron:\n",
        "#perceptron class defines the constructor (__init__method),which initializes key parameters of the perception model\n",
        "  def __init__(self,input_size,learning_rate=0.1,epochs=100):\n",
        "    self.weights=np.zeros(input_size)\n",
        "    self.bias=0\n",
        "    self.learning_rate=learning_rate\n",
        "    self.epochs=epochs\n",
        "\n",
        "#defining activation function\n",
        "  def activation(self,x):\n",
        "    return 1 if x>=0 else 0  #step function\n",
        "\n",
        "#predict method is responsible for forward propagation in the perceptron model\n",
        "#it takes an input vector x,computes the weighted sum,applies the activation function, and returns the predicted output\n",
        "  def predict(self,x):\n",
        "    z=np.dot(self.weights,x)+self.bias\n",
        "    return self.activation(z)\n",
        "\n",
        "#train method is responsible for training the perceptron model using labeled input data\n",
        "#it follows the perceptron learning algorithm,adjusting weights iteratively based on classification errors\n",
        "  def train(self,X,y):\n",
        "    for epoch in range(self.epochs):\n",
        "      updates=0 #track updates to check convergence\n",
        "      for i in range(len(X)):\n",
        "        prediction=self.predict(X[i])\n",
        "        error=y[i]-prediction\n",
        "        if error!=0:\n",
        "          self.weights+=self.learning_rate*error*X[i]\n",
        "          self.bias+=self.learning_rate*error\n",
        "          updates+=1\n",
        "      if updates==0:#if no updates,training is complete\n",
        "        print(f\"Converged at epoch {epoch+1}\")\n",
        "        break\n",
        "\n",
        "#example usage\n",
        "X=np.array([[0,0],[0,1],[1,0],[1,1]]) #input features\n",
        "y=np.array([0,0,0,1])#AND Gate labels\n",
        "\n",
        "perceptron=perceptron(input_size=2)\n",
        "perceptron.train(X,y)\n",
        "\n",
        "#Testing\n",
        "for x in X:\n",
        "  print(f\"Input:{x},Predicted Output: {perceptron.predict(x)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvoMZAIYxYbj",
        "outputId": "fc033a55-acd0-499d-8dda-0a71e88105fb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at epoch 4\n",
            "Input:[0 0],Predicted Output: 0\n",
            "Input:[0 1],Predicted Output: 0\n",
            "Input:[1 0],Predicted Output: 0\n",
            "Input:[1 1],Predicted Output: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Perceptron model, a basic kind of artificial neural network used for binary classification, is implemented by this code.  The AND gate, which produces 1 only when both inputs are 1 and 0 otherwise, is taught to the perceptron."
      ],
      "metadata": {
        "id": "n07unxiXroui"
      }
    }
  ]
}